{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *checkpoint_schedule* application: Adjoint-Based Gradient with Burger's Equation\n",
    "\n",
    "This user example shows adjoint-based gradient computation using the *checkpointing_schedules* package. We initially define the adjoint-based gradient problem and then present the forward and adjoint solvers prescribed by the *checkpointing_schedules* package.\n",
    "\n",
    "## Defining the application\n",
    "\n",
    "Let us consider a one-dimensional (1D) problem aiming to compute the gradient/sensitivity of an objective functional $I$ with respect to a control parameter. The objective functional is given by the expression:\n",
    "\n",
    "$$\n",
    "I(u_0) = \\int_{\\Omega} \\frac{1}{2} u(x, \\tau)u(x, \\tau) \\, dx\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "This measures the energy of a 1D velocity variable $u = u(x, \\tau)$ at a time $\\tau$, where $u$ is governed by the 1D viscous Burgers equation, a non-linear equation for the advection and diffusion of momentum:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} - \\nu \\frac{\\partial^2 u}{\\partial x^2} = 0.\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "Here, $x \\in [0, L]$ is the space variable, and $t \\in \\mathbb{R}^{+}$ represents the time variable. The boundary condition is $u(0, t) = u(L, t) = 0$, where $L$ is the length of the 1D domain. The initial condition is given by $u_0 = \\sin(\\pi x)$.\n",
    "\n",
    "The control parameter is the initial condition $u_0$. Hence, the objective is to compute the adjoint-based gradient of the functional $I(u_0)$ with respect to $u_0$.\n",
    "\n",
    "This example sets the adjoint equation from the continuous formulation, meaning the adjoint PDE is obtained from the continuous forward PDE (Partial Differential Equation). The adjoint-based gradient is given by the expression:\n",
    "\n",
    "$$\n",
    "\\nabla_{u_0} I = \\int_{\\Omega}  \\lambda(x, 0) \\delta u_0 \\, dx,\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "where $\\lambda(x, 0)$ is the adjoint variable governed by the adjoint system:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\lambda}{\\partial t} - \\lambda \\frac{\\partial u}{\\partial x} + u \\frac{\\partial \\lambda}{\\partial x} + \\nu \\frac{\\partial^2 \\lambda}{\\partial x^2} = 0,\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "satisfying the boundary condition $\\lambda (0, t) = \\lambda(L, t) = 0$. In this case, the initial condition is $\\lambda (x, \\tau) = u(x, \\tau)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burger's equation solver\n",
    "\n",
    "The sensitivity computation is performed by solving the forward and adjoint equations. The forward equation is 1D viscous Burgers equation (2). For this current sensitivity problem, the adjoint equation is given by (4). \n",
    "\n",
    "To solve forward and adjoint solvers, we implement `BurgersEquation` class that execute the forward and adjoint solvers. In addition, the `BurgersEquation` has the `copy_data` that copies the data from one storage type to another, and `adjoint_initial_condition` that sets the adjoint initial condition.\n",
    "\n",
    "Both the forward and adjoint systems are discretised using the Finite Element Method (FEM). We use the first-order Lagrange basis functions to discretise the spatial domain. The backward finite difference method is employed to discretise the equations in time.\n",
    "\n",
    "After discretising, the forward and adjoint systems are written in the following form:\n",
    "$$M \\frac{\\mathbf{U}^{n+1} - \\mathbf{U}^n}{\\Delta t} - K \\mathbf{U}^{n+1} + C(\\mathbf{U}^{n+1}) \\mathbf{U}^{n+1} = 0,$$\n",
    "$$M \\frac{\\boldsymbol{\\Lambda}^{n} - \\boldsymbol{\\Lambda}^{n+1}}{\\Delta t} - K \\boldsymbol{\\Lambda}^{n} + C(\\mathbf{U}^{n})^T \\boldsymbol{\\Lambda}^{n} + C_1(\\mathbf{U}^{n}) \\boldsymbol{\\Lambda}^{n} = 0,$$\n",
    "where $M$, $K$ are the mass and stiffness. $U$ represents the solution vector, and $\\Lambda$ is the adjoint solution vector. The matrices $C$ and $C_1$ are obtained from the convection terms. The superscript $n$ denotes the time step, and $\\Delta t$ is the time step size. The solution vector $\\mathbf{U}^{n+1}$ is obtained by solving the non-linear forward system using the Newton method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enum import Enum\n",
    "import os\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.optimize import newton\n",
    "\n",
    "\n",
    "class BurgersEquation:\n",
    "    \"\"\"This class is capable to solve the time-dependent forward \n",
    "    and adjoint burger's equation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : dict\n",
    "        The model parameters containing the essential information to solve\n",
    "        the burger's equation.\n",
    "    init_condition : array\n",
    "        The initial condition used to solve the forward burger's equation.\n",
    "    mesh : array\n",
    "        The spatial mesh.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, forward_initial_condition, mesh):\n",
    "        self.model = model\n",
    "        self.mesh = mesh\n",
    "        self.forward_work_memory = {StorageType.WORK: {}}\n",
    "        self.forward_work_memory[StorageType.WORK][0] = forward_initial_condition\n",
    "        self.forward_final_solution = None\n",
    "        self.adjoint_work_memory = {StorageType.WORK: {}}\n",
    "        self.restart_forward = {StorageType.RAM: {}, StorageType.DISK: {}}\n",
    "        self.adjoint_dependency = {StorageType.WORK: {}, StorageType.RAM: {}, StorageType.DISK: {}}\n",
    "        self.mode = \"forward\"\n",
    "\n",
    "    def forward(\n",
    "            self, n0, n1, storage=None, write_adj_deps=False,\n",
    "            write_ics=False, single_storage=False\n",
    "    ):\n",
    "        \"\"\"Solve the non-linear forward burger's equation in time.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n0 : int\n",
    "            Initial time step.\n",
    "        n1 : int\n",
    "            Final time step.\n",
    "        storage : StorageType, optional\n",
    "            The storage type, which can be StorageType.RAM, StorageType.DISK,\n",
    "            StorageType.WORK, or StorageType.NONE.\n",
    "        write_adj_deps : bool, optional\n",
    "            Whether the adjoint dependency data will be stored.\n",
    "        write_ics : bool, optional\n",
    "            Whether the forward restart data will be stored.\n",
    "        single_storage : bool, optional\n",
    "            This parameter is used to indicated whether a checkpointing schedule\n",
    "            is single storage or not. Single storage means that no checkpointing\n",
    "            algorithm (eg, `Revolve`, `HRevole`) is employed. \n",
    "        \"\"\"\n",
    "        M = self._mass_matrix()\n",
    "        K = self._stiffness_matrix()\n",
    "\n",
    "        def _non_linear(u_new, u):\n",
    "            \"\"\"Define the non-linear system.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            u_new : array\n",
    "                Forward solution at the `n + 1` time step.\n",
    "            u : array\n",
    "                Forward solution at the `n` time step.\n",
    "            \"\"\"\n",
    "            C = self._convection_matrix(u_new)\n",
    "            # Set the boundary conditions.\n",
    "            u[0] = u[self.model[\"nx\"] - 1] = 0\n",
    "            F = (M + self.model[\"dt\"] * (- K + C)) * u_new - M * u\n",
    "            return F\n",
    "\n",
    "        # Get the initial condition\n",
    "        u = self.forward_work_memory[StorageType.WORK][n0]\n",
    "        del self.forward_work_memory[StorageType.WORK][n0]\n",
    "        if write_ics:\n",
    "            self.restart_forward[storage][n0] = u.copy()\n",
    "        u_new = u.copy()\n",
    "        n1 = min(n1, self.model[\"max_n\"])\n",
    "        step = n0\n",
    "        if write_adj_deps:\n",
    "            self.adjoint_dependency[storage][step] = u\n",
    "        while step < n1:    \n",
    "            u_new = newton(lambda u_new: _non_linear(u_new, u), u)\n",
    "            step += 1\n",
    "            u = u_new.copy()\n",
    "            if write_adj_deps:\n",
    "                self.adjoint_dependency[storage][step] = u\n",
    "        if step == self.model[\"max_n\"]:\n",
    "            self.forward_final_solution = u_new.copy()\n",
    "        if (not write_adj_deps \n",
    "           or (self.mode == \"forward\" and step < self.model[\"max_n\"])\n",
    "        ):\n",
    "            self.forward_work_memory[StorageType.WORK][step] = u_new.copy()\n",
    "\n",
    "    def adjoint(self, n0, n1, clear_adj_deps, single_storage=False):\n",
    "        \"\"\"Execute the adjoint equation in time.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        n0 : int\n",
    "            Initial time step.\n",
    "        n1 : int\n",
    "            Final time step.\n",
    "        clear_adj_deps : bool\n",
    "            If `True`, the adjoint dependency data will be cleared.\n",
    "        \"\"\"\n",
    "        u = self.adjoint_work_memory[StorageType.WORK][n1]\n",
    "        del self.adjoint_work_memory[StorageType.WORK][n1]\n",
    "        u_new = np.zeros(self.model[\"nx\"])\n",
    "        steps = n1 - n0\n",
    "        t = n1\n",
    "        M = self._mass_matrix()\n",
    "        K = self._stiffness_matrix()\n",
    "        for _ in range(steps):\n",
    "            u[0] = u[self.model[\"nx\"] - 1] = 0\n",
    "            C = self._convection_matrix(self.adjoint_dependency[StorageType.WORK][t - 1])\n",
    "            C1 = self._convection_matrix_2(self.adjoint_dependency[StorageType.WORK][t - 1])\n",
    "            A = M + self.model[\"dt\"] * (- K + C.T + C1)\n",
    "            d = M * u\n",
    "            u_new = spsolve(A, d)\n",
    "            u = u_new.copy()\n",
    "            if clear_adj_deps:\n",
    "                del self.adjoint_dependency[StorageType.WORK][t - 1]\n",
    "            t -= 1\n",
    "        self.adjoint_work_memory[StorageType.WORK][n0] = u_new\n",
    "\n",
    "    def copy_data(self, step, from_storage, to_storage, move=False, single_storage=False):\n",
    "        \"\"\"Copy data from one storage to another.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        step : int\n",
    "            The time step.\n",
    "        from_storage : StorageType\n",
    "            The storage type from which the data will be copied.\n",
    "        to_storage : StorageType\n",
    "            The storage type to which the data will be copied.\n",
    "        move : bool, optional\n",
    "            Whether the data will be moved or not. If `True`, the data will be\n",
    "            removed from the `from_storage`.\n",
    "        \"\"\"\n",
    "        if to_storage == StorageType.WORK:\n",
    "            if single_storage:\n",
    "                self.adjoint_dependency[StorageType.WORK][step] = self.adjoint_dependency[from_storage][step]\n",
    "            else:\n",
    "                self.forward_work_memory[StorageType.WORK][step] = self.restart_forward[from_storage][step]\n",
    "        else:\n",
    "            self.restart_forward[to_storage][step] = self.restart_forward[from_storage][step]\n",
    "        if move:\n",
    "            if single_storage:\n",
    "                del self.adjoint_dependency[from_storage][step]\n",
    "            else:\n",
    "                del self.restart_forward[from_storage][step]\n",
    "\n",
    "    def adjoint_initial_condition(self):\n",
    "        \"\"\"Set the adjoint initial condition.\n",
    "        \"\"\"\n",
    "        self.mode = \"adjoint\"\n",
    "        u = self.forward_final_solution\n",
    "        self.adjoint_work_memory[StorageType.WORK][self.model[\"max_n\"]] = u\n",
    "\n",
    "    def _mass_matrix(self):\n",
    "        \"\"\"This function assembles the mass matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        M : scipy.sparse.lil_matrix\n",
    "            The mass matrix.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        The mass matrix is assembled a linear spatial basis functions.\n",
    "        \"\"\"\n",
    "        num_nodes = self.model[\"nx\"]\n",
    "        M = lil_matrix((num_nodes, num_nodes))\n",
    "        M[0, 0] = M[num_nodes - 1, num_nodes - 1] = 1/3\n",
    "        M[0, 1] = M[num_nodes - 1, num_nodes - 2] = 1/6\n",
    "        for i in range(1, num_nodes - 1):\n",
    "            M[i, i - 1] = M[i, i + 1] = 1/6\n",
    "            M[i, i] = 2/3\n",
    "        return M\n",
    "    \n",
    "    def _stiffness_matrix(self):\n",
    "        \"\"\"This function assembles the stiffness matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        K : scipy.sparse.lil_matrix\n",
    "            The stiffness matrix.\n",
    "        \"\"\"\n",
    "        num_nodes = self.model[\"nx\"]\n",
    "        h = self.model[\"lx\"] / self.model[\"nx\"] \n",
    "        # 1D mesh is uniform. Thus, the mesh spacing is constant.\n",
    "        b = self.model[\"nu\"] / (h ** 2)\n",
    "        # local_stiffness = np.array([[-1, 1], [1, -1]])\n",
    "        K = lil_matrix((num_nodes, num_nodes))\n",
    "        K[0, 0] = K[num_nodes - 1, num_nodes - 1] = - b\n",
    "        K[0, 1] = K[num_nodes - 1, num_nodes - 2] = + b\n",
    "        for i in range(1, num_nodes - 1):\n",
    "            K[i, i - 1] = K[i, i + 1] = b\n",
    "            K[i, i] = - 2 * b\n",
    "        return K\n",
    "    \n",
    "    def _convection_matrix(self, u, adjoint=False):\n",
    "        \"\"\"This function assembles the convection matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        u : array\n",
    "            State vector.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C : scipy.sparse.lil_matrix\n",
    "            The convection matrix.\n",
    "        \"\"\"\n",
    "        num_nodes = self.model[\"nx\"]\n",
    "        # 1D mesh is uniform. Thus, the mesh spacing is constant.\n",
    "        h = self.model[\"lx\"] / self.model[\"nx\"] \n",
    "        C = lil_matrix((num_nodes, num_nodes))\n",
    "        C[0, 0] = - (1/3 * u[0] / h + 1/6 * u[1] / h)\n",
    "        C[num_nodes - 1, num_nodes - 1] = 1/3 * u[num_nodes - 1] / h + 1/6 * u[num_nodes - 2] / h\n",
    "        C[0, 1] = - C[0, 0]\n",
    "        C[num_nodes - 1, num_nodes - 2] = - C[num_nodes - 1, num_nodes - 1]\n",
    "        for i in range(1, num_nodes - 1):\n",
    "            C[i, i - 1] = - (1/6 * u[i - 1] / h + 1/3 * u[i] / h)\n",
    "            C[i, i] = (1/6 * u[i - 1] / h - 1/6 * u[i + 1] / h)\n",
    "            C[i, i + 1] = (1/6 * u[i + 1] / h + 1/3 * u[i] / h)\n",
    "        return C\n",
    "    \n",
    "    def _convection_matrix_2(self, u_forward):\n",
    "        \"\"\"This function assembles the convection matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        u_forward : _type_\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        num_nodes = self.model[\"nx\"]\n",
    "        # 1D mesh is uniform. Thus, the mesh spacing is constant.\n",
    "        h = self.model[\"lx\"] / self.model[\"nx\"] \n",
    "        C = lil_matrix((num_nodes, num_nodes))\n",
    "        C[0, 0] = (- u_forward[0] + u_forward[1]) / (3 * h)\n",
    "        C[0, 1] = (- u_forward[0] + u_forward[1]) / (6 * h)\n",
    "        C[num_nodes - 1, num_nodes - 1] = (u_forward[num_nodes - 1] - u_forward[num_nodes - 2]) / (3 * h)\n",
    "        C[num_nodes - 1, num_nodes - 2] = (u_forward[num_nodes - 1] - u_forward[num_nodes - 2]) / (6 * h)\n",
    "        for i in range(1, num_nodes - 1):\n",
    "            C[i, i - 1] = (- u_forward[i - 1] + u_forward[i]) / (6 * h)\n",
    "            C[i, i] = (- u_forward[i - 1] + u_forward[i + 1]) / (3 * h)\n",
    "            C[i, i + 1] = (u_forward[i + 1] - u_forward[i]) / (6 * h)\n",
    "        return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing\n",
    "The adjoint PDE is then solved in a reverse time order and it depends on the forward solution (see the adjoint equation (4)). Therefore, to store the forward state variable is required. Storing the entire forward state in preparation for the adjoint calculation has a memory footprint linear in the number of time steps. For sufficiently large problems this can exhaust the\n",
    "memory of a computer system. To overcome this kind of problem, checkpointing algorithms are used to reduce the memory usage.\n",
    "\n",
    "To employ a checkpointing method in the current adjoint-based sensitivity, we define a `CheckpointingManager` to manage the execution of forward and adjoint models. The `CheckpointingManager` contains the `execute` method, which performs each action specified in the checkpoint schedule (`_schedule`). Within the `execute` method, we have the single-dispatch generic `action` function that is overloaded by particular functions. For instance, if the `checkpoint_schedule` action is `Forward`, the `action_forward` function is called. Within this function, the necessary code is implemented to progress the forward equation. In this particular example, the forward solver is executed by calling `self.equation.forward`. Here, `self.equation` is an attribute of `CheckpointingManager`. Similarly, the adjoint solver is executed by calling `self.equation.adjoint` within the `action_reverse` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools, sys\n",
    "from checkpoint_schedules import *\n",
    "class CheckpointingManager:\n",
    "    \"\"\"Manage the forward and adjoint solvers.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    schedule : CheckpointSchedule\n",
    "        The schedule created by `checkpoint_schedules` package.\n",
    "    equation : object\n",
    "        An equation object used to solve the forward and adjoint solvers.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The `equation` object contains methods to execute the forward and adjoint. In \n",
    "    addition, it contains methods to copy data from one storage to another, and\n",
    "    to set the initial condition for the adjoint.\n",
    "    \"\"\"\n",
    "    def __init__(self, schedule, equation):\n",
    "        self.max_n = sys.maxsize\n",
    "        self.equation = equation\n",
    "        self.reverse_step = 0\n",
    "        self._schedule = schedule\n",
    "        self.single_storage = False\n",
    "        if (\n",
    "                isinstance(self._schedule, SingleMemoryStorageSchedule) \n",
    "                or isinstance(self._schedule, SingleDiskStorageSchedule)\n",
    "        ):\n",
    "            self.single_storage = True\n",
    "        \n",
    "    def execute(self):\n",
    "        \"\"\"Execute forward and adjoint using checkpointing.\n",
    "        \"\"\"\n",
    "        @functools.singledispatch\n",
    "        def action(cp_action):\n",
    "            raise TypeError(\"Unexpected action\")\n",
    "\n",
    "        @action.register(Forward)\n",
    "        def action_forward(cp_action):\n",
    "            n1 = cp_action.n1\n",
    "            self.equation.forward(cp_action.n0, n1, storage=cp_action.storage,\n",
    "                                  single_storage=self.single_storage,\n",
    "                                  write_adj_deps=cp_action.write_adj_deps,\n",
    "                                  write_ics=cp_action.write_ics)\n",
    "            if n1 >= self.equation.model[\"max_n\"]:\n",
    "                n1 = min(n1, self.equation.model[\"max_n\"])\n",
    "                self._schedule.finalize(n1)\n",
    "\n",
    "        @action.register(Reverse)\n",
    "        def action_reverse(cp_action):\n",
    "            if self.reverse_step == 0:\n",
    "                self.equation.adjoint_initial_condition()\n",
    "            self.equation.adjoint(cp_action.n0, cp_action.n1, cp_action.clear_adj_deps, single_storage=self.single_storage)\n",
    "            self.reverse_step += cp_action.n1 - cp_action.n0\n",
    "            \n",
    "        @action.register(Copy)\n",
    "        def action_copy(cp_action):\n",
    "            self.equation.copy_data(cp_action.n, cp_action.from_storage, cp_action.to_storage,\n",
    "                                    move=False, single_storage=self.single_storage)\n",
    "\n",
    "        @action.register(Move)\n",
    "        def action_move(cp_action):\n",
    "            self.equation.copy_data(cp_action.n, cp_action.from_storage, cp_action.to_storage,\n",
    "                                    move=True, single_storage=self.single_storage)\n",
    "            \n",
    "        @action.register(EndForward)\n",
    "        def action_end_forward(cp_action):\n",
    "            if self._schedule.max_n is None:\n",
    "                self._schedule._max_n = self.max_n\n",
    "            assert self.reverse_step == 0\n",
    "            \n",
    "        @action.register(EndReverse)\n",
    "        def action_end_reverse(cp_action):\n",
    "            if self._schedule.max_n != self.reverse_step:\n",
    "                raise ValueError(\"The number of steps in the reverse phase\"\n",
    "                                 \"is different from the number of steps in the\"\n",
    "                                 \"forward phase.\")\n",
    "            \n",
    "        self.reverse_step = 0\n",
    "        for _, cp_action in enumerate(self._schedule):\n",
    "            action(cp_action)\n",
    "            if isinstance(cp_action, EndReverse):\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjoint-based sensitivity computations\n",
    "\n",
    "The purpose of this adjoint-based sensitivity computation is to use every checkpointing approach available in the `checkpoint_schedules` package and verify the consistent of the results. We employ a fundamental tool used in verification of gradients, which is the\n",
    "*second order Taylor remainder convergence test*. Thus, let us consider the functional $I(u_0)$  and $\\nabla_{u_0}$ be its gradient with respect to the control parameter $u_0$. Let $u$ be the solution of the forward problem, and let $\\delta u$ be a perturbation to $u$. Therefore, the *Taylor remainder convergence test* is given by the expression: \n",
    "$$ \\left|I(u + \\delta u) - I(u) - \\nabla_{u_0} I \\cdot \\delta u\\right| \\rightarrow 0 \\quad \\mathrm{at} \\ O(\\delta u^2).$$\n",
    "\n",
    "In the next sections, we present the results of the adjoint-based sensitivity computation using the `checkpoint_schedules` package and the *Taylor remainder convergence test*. It is expected the convergence rate of the *Taylor remainder convergence test* is approximately $2$ in every checkpointing approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor_remainder_test(adjoint_solution, J, u0):\n",
    "    epsilons = [0.05 / 2**i for i in range(4)]\n",
    "    E = []\n",
    "    h = u0\n",
    "    for eps in epsilons:\n",
    "        up = u0 + h * eps\n",
    "        dJdm = sum(adjoint_solution[StorageType.WORK][0].reshape(-1) * h.reshape(-1)) * 1 / model[\"nx\"]\n",
    "        burgers = BurgersEquation(model, up, mesh)\n",
    "        burgers.forward(0, model[\"max_n\"])\n",
    "        # Functional value at the perturbed state.\n",
    "        u2 = burgers.forward_final_solution**2\n",
    "        Jp = sum(u2.reshape(-1) * 0.5) * 1 / model[\"nx\"]\n",
    "        E.append(abs(Jp - J - dJdm * eps))\n",
    "    return E, epsilons\n",
    "\n",
    "def convergence_rates(E_values, eps_values, show=True):\n",
    "    from numpy import log\n",
    "    r = []\n",
    "    for i in range(1, len(eps_values)):\n",
    "        r.append(log(E_values[i] / E_values[i - 1])\n",
    "                 / log(eps_values[i] / eps_values[i - 1]))\n",
    "    if show:\n",
    "        print(\"Computed convergence rates: {}\".format(r))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define the `model` dictionary containing the parameters required for the forward and adjoint solvers. The `model` dictionary is then passed to the `BurgersEquation` class. Additionally, we set up the 1D mesh and the initial condition for the forward Burgers' solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\"lx\": 1,   # lenght domain\n",
    "         \"nx\": 100,  # number of nodes\n",
    "         \"dt\": 0.0005,  # time step\n",
    "         \"nu\": 0.01,  # viscosity\n",
    "         \"max_n\": 500,  # total steps\n",
    "         \"chk_ram\": 50,  # number of checkpoints in RAM\n",
    "         \"chk_disk\": 50,  # number of checkpoints on disk\n",
    "        }\n",
    "mesh = np.linspace(0, model[\"lx\"], model[\"nx\"]) # create the spatial grid\n",
    "u0 = np.sin(np.pi*mesh) # initial condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjoint-based sensitivity is initially computed using the `SingleMemoryStorageSchedule` checkpointing approach. The `SingleMemoryStorageSchedule` stores the forward data of each time-step in working memory. As explained in the [notebook with illustrative example](https://nbviewer.org/github/firedrakeproject/checkpoint_schedules/blob/main/docs/notebooks/tutorial.ipynb), this schedule does not require the maximal step (`model[\"max_n\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ddolci/work/my_venv/lib/python3.11/site-packages/scipy/optimize/_zeros_py.py:482: RuntimeWarning: some failed to converge after 50 iterations\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.99360272596985, 1.9872798748302887, 1.9378150121167665]\n",
      "Adjoint-based sensitivity: 0.45823268843319326\n"
     ]
    }
   ],
   "source": [
    "schedule = SingleMemoryStorageSchedule()  # Create the checkpointing schedule.\n",
    "burger = BurgersEquation(model, u0, mesh)  # Create the burger's equation object.\n",
    "manager = CheckpointingManager(schedule, burger)  # Create the checkpointing manager.\n",
    "manager.execute()  # execute the checkpointing schedule using `SingleMemoryStorageSchedule` schedule.\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows the usage of the `SingleDiskStorageSchedule` schedule. In this case, the forward data used in the adjoint computations is only stored on disk. The `SingleDiskStorageSchedule` schedule does not require the definition of the maximal step `model[\"max_n\"]` before the execution of the forward solver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "schedule = SingleDiskStorageSchedule()  # Create the checkpointing schedule.\n",
    "burger = BurgersEquation(model, u0, mesh)  # Create the burger's equation object.\n",
    "manager = CheckpointingManager(schedule, burger)  # Create the checkpointing manager.\n",
    "manager.execute()  # execute the checkpointing schedule using `SingleMemoryStorageSchedule` schedule.\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the example above, we do not move any data from the disk to the work in memory, i.e., we copy the data from the disk and keep it on disk. The next example shows the usage of the `SingleDiskStorageSchedule` schedule with the `mode_data=True` argument. In this case, the forward data used in the adjoint compuations stored on disk is moved to the work in memory, i.e., we copy the data from the disk and remove it from the disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "schedule = SingleDiskStorageSchedule(move_data=True)  # Create the checkpointing schedule.\n",
    "burger = BurgersEquation(model, u0, mesh)  # Create the burger's equation object.\n",
    "manager = CheckpointingManager(schedule, burger)  # Create the checkpointing manager.\n",
    "manager.execute()  # execute the checkpointing schedule using `SingleMemoryStorageSchedule` schedule.\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example uses the `Revolve` schedule [1]. The `Revolve` algorithm requires the definition of the maximal step `model[\"max_n\"]` before the execution of the forward solver, and also the specification of the number of checkpoints stored in RAM (Random Access Memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "burger = BurgersEquation(model, u0, mesh) # create the burger's equation object\n",
    "schedule = Revolve(model[\"max_n\"], model[\"chk_ram\"]) # create the checkpointing schedule\n",
    "manager = CheckpointingManager(schedule, burger)  # create the checkpointing manager\n",
    "manager.execute()  # execute the forward and adjoint solvers using checkpointing\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DiskRevolve` [3] schedule requires the definition of the maximal step `model[\"max_n\"]` before the execution of the forward solver, and the maximum number of checkpoints to be saved in RAM. This schedule automatically computes the number of checkpoints to store on disk, considering factors such as:\n",
    "- Computational cost to execute the forward solver in one step.\n",
    "- Computational cost to store the forward data on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "burger = BurgersEquation(model, u0, mesh) # create the burger's equation object\n",
    "schedule = DiskRevolve(model[\"max_n\"], model[\"chk_ram\"]) # create the checkpointing schedule\n",
    "manager = CheckpointingManager(schedule, burger)  # create the checkpointing manager\n",
    "manager.execute()  # execute the forward and adjoint solvers using checkpointing\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PeriodicDiskRevolve` [4] schedule also requires the definition of the maximal step `model[\"max_n\"]` before the execution of the forward solver. This schedule automatically calculates the number of steps stored on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use periods of size  51\n",
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "burger = BurgersEquation(model, u0, mesh) # create the burger's equation object\n",
    "schedule = PeriodicDiskRevolve(model[\"max_n\"], model[\"chk_ram\"]) # create the checkpointing schedule\n",
    "manager = CheckpointingManager(schedule, burger)  # create the checkpointing manager\n",
    "manager.execute()  # execute the forward and adjoint solvers using checkpointing\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following examples, we employ the `HRevolve` [5] and `MultistageCheckpointSchedule` [2] schedules. These checkpointing schedules require the definition of the maximal step `model[\"max_n\"]` before the execution of the forward solver. In these schedules, we specify the maximum number of checkpoints to be stored on disk (`model[\"chk_disk\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "burger = BurgersEquation(model, u0, mesh) # create the burger's equation object\n",
    "schedule = HRevolve(model[\"max_n\"], model[\"chk_ram\"], model[\"chk_disk\"]) # create the checkpointing schedule\n",
    "manager = CheckpointingManager(schedule, burger)  # create the checkpointing manager\n",
    "manager.execute()  # execute the forward and adjoint solvers using checkpointing\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "burger = BurgersEquation(model, u0, mesh) # create the burger's equation object\n",
    "schedule = MultistageCheckpointSchedule(model[\"max_n\"], model[\"chk_ram\"], model[\"chk_disk\"]) # create the checkpointing schedule\n",
    "manager = CheckpointingManager(schedule, burger)  # create the checkpointing manager\n",
    "manager.execute()  # execute the forward and adjoint solvers using checkpointing\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TwoLevelCheckpointSchedule` [6] does not require the maximal step `model[\"max_n\"]` to be defined before the execution of the forward solver, saves the forward restart data on disk based on the `period` argument. For instance, if `period = 10`, the forward restart data is stored every ten steps on disk.\n",
    "\n",
    "During the adjoint computation, the user can define additional storage of the forward restart data. This is carried out according to the `binomial_storage` argument. The additional number of checkpoints stored is set by the second argument of the `TwoLevelCheckpointSchedule` class. In the example below, we set `model[\"chk_ram\"]` as the additional number of checkpoints to be stored during the adjoint computation, and the storage type is in RAM (`binomial_storage=StorageType.RAM`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "burger = BurgersEquation(model, u0, mesh) # create the burger's equation object\n",
    "period = 10\n",
    "schedule = TwoLevelCheckpointSchedule(period, model[\"chk_ram\"], binomial_storage=StorageType.RAM) # create the checkpointing schedule\n",
    "manager = CheckpointingManager(schedule, burger)  # create the checkpointing manager\n",
    "manager.execute()  # execute the forward and adjoint solvers using checkpointing\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define to store the additional forward restart data on disk (`binomial_storage=StorageType.DISK`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed convergence rates: [1.9935945213147765, 1.9872476910156494, 1.9376937399361267]\n",
      "Adjoint-based sensitivity: 0.45823268734941364\n"
     ]
    }
   ],
   "source": [
    "burger = BurgersEquation(model, u0, mesh) # create the burger's equation object\n",
    "period = 10\n",
    "schedule = TwoLevelCheckpointSchedule(period, model[\"chk_disk\"], binomial_storage=StorageType.DISK) # create the checkpointing schedule\n",
    "manager = CheckpointingManager(schedule, burger)  # create the checkpointing manager\n",
    "manager.execute()  # execute the forward and adjoint solvers using checkpointing\n",
    "u_2 = burger.forward_final_solution**2  # Compute the energy.\n",
    "J = sum(u_2.reshape(-1) * 0.5) * 1/burger.model[\"nx\"]  # Compute the functional value.\n",
    "E, h = taylor_remainder_test(burger.adjoint_work_memory, J, u0)  # Compute the Taylor remainder.\n",
    "convergence_rates(E, h, show=True)\n",
    "senstivity = sum(burger.adjoint_work_memory[StorageType.WORK][0].reshape(-1) * u0.reshape(-1)) * 1 / model[\"nx\"]\n",
    "print(\"Adjoint-based sensitivity: {}\".format(senstivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Remarks\n",
    "Every adjoint-based sensitivity with different schedules presented consistent results. The convergence rate of the *Taylor remainder convergence test* is approximately $2$ for every case, and the adjoint-based sensitivity has the same value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Griewank, A., & Walther, A. (2000). Algorithm 799: revolve: an implementation of checkpointing for the reverse or adjoint mode of computational differentiation. ACM Transactions on Mathematical Software (TOMS), 26(1), 19-45., doi: https://doi.org/10.1145/347837.347846\n",
    "\n",
    "[2] Stumm, P., & Walther, A. (2009). Multistage approaches for optimal offline checkpointing. SIAM Journal on Scientific Computing, 31(3), 1946-1967. https://doi.org/10.1137/080718036\n",
    "\n",
    "[3] Aupy, G., Herrmann, J., Hovland, P., & Robert, Y. (2016). Optimal multistage algorithm for adjoint computation. SIAM Journal on Scientific Computing, 38(3), C232-C255. DOI: https://doi.org/10.1145/347837.347846.\n",
    "\n",
    "[4] Aupy, G., & Herrmann, J. (2017). Periodicity in optimal hierarchical checkpointing schemes for adjoint computations. Optimization Methods and Software, 32(3), 594-624. doi: https://doi.org/10.1080/10556788.2016.1230612\n",
    "\n",
    "[5] Herrmann, J. and Pallez (Aupy), G. (2020). H-Revolve: a framework for adjoint computation on synchronous hierarchical platforms. ACM Transactions on Mathematical Software (TOMS), 46(2), 1-25. DOI: https://doi.org/10.1145/3378672.\n",
    "\n",
    "[6] Pringle, G. C., Jones, D. C., Goswami, S., Narayanan, S. H. K., and  Goldberg, D. (2016). Providing the ARCHER community with adjoint modelling tools for high-performance oceanographic and cryospheric computation. https://nora.nerc.ac.uk/id/eprint/516314."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
